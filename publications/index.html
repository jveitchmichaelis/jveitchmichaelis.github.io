<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Josh Veitch-Michaelis</title> <meta name="author" content="Josh Veitch-Michaelis"/> <meta name="description" content=""/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üöÄ</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jveitchmichaelis.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Josh¬†</span>Veitch-Michaelis</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div> <div id="veitchmichaelis2024oamtcdgloballydiversedataset" class="col-sm-8"> <div class="title">OAM-TCD: A globally diverse dataset of high-resolution tree cover maps</div> <div class="author"> <em>Josh Veitch-Michaelis</em>,¬†Andrew Cottam,¬†Daniella Schweizer, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Eben N. Broadbent, David Dao, Ce Zhang, Angelica Almeyda Zambrano, Simeon Max' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">5 more authors</span> </div> <div class="periodical"> <em></em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dx.doi.org/10.48550/arXiv.2407.11743" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.48550/arXiv.2407.11743</a> </div> <div class="abstract hidden"> <p>Accurately quantifying tree cover is an important metric for ecosystem monitoring and for assessing progress in restored sites. Recent works have shown that deep learning-based segmentation algorithms are capable of accurately mapping trees at country and continental scales using high-resolution aerial and satellite imagery. Mapping at high (ideally sub-meter) resolution is necessary to identify individual trees, however there are few open-access datasets containing instance level annotations and those that exist are small or not geographically diverse. We present a novel open-access dataset for individual tree crown delineation (TCD) in high-resolution aerial imagery sourced from OpenAerialMap (OAM). Our dataset, OAM-TCD, comprises 5072 2048x2048 px images at 10 cm/px resolution with associated human-labeled instance masks for over 280k individual and 56k groups of trees. By sampling imagery from around the world, we are able to better capture the diversity and morphology of trees in different terrestrial biomes and in both urban and natural environments. Using our dataset, we train reference instance and semantic segmentation models that compare favorably to existing state-of-the-art models. We assess performance through k-fold cross-validation and comparison with existing datasets; additionally we demonstrate compelling results on independent aerial imagery captured over Switzerland and compare to municipal tree inventories and LIDAR-derived canopy maps in the city of Zurich. Our dataset, models and training/benchmark code are publicly released under permissive open-source licenses: Creative Commons (majority CC BY 4.0), and Apache 2.0 respectively. </p> </div> </div> </div> </li></ol> <h2 class="year">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Sci. Rep.</abbr></div> <div id="PPR:PPR534649" class="col-sm-8"> <div class="title">In-orbit demonstration of a re-trainable Machine Learning Payload for processing optical imagery</div> <div class="author"> Gonzalo Mateo-Garc√≠a,¬†<em>Josh Veitch-Michaelis</em>,¬†Cormac Purcell, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Nicolas Longepe, Pierre Philippe Mathieu, Simon Reid, Alice Anlind, Fredrik Bruhn, James Parr' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">6 more authors</span> </div> <div class="periodical"> <em>Scientific Reports</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dx.doi.org/10.10238/s41598-023-34436-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.10238/s41598-023-34436-w</a> </div> <div class="abstract hidden"> <p>Cognitive cloud computing in space (3CS) describes a new frontier of space innovation powered by Artificial Intelligence, enabling an explosion of new applications in observing our planet and enabling deep space exploration. In this framework, machine learning (ML) payloads ‚Äìisolated software capable of extracting high level information from onboard sensors‚Äì are key to accomplish this vision. In this work we demonstrate, in a satellite deployed in orbit, a ML payload called ‚ÄòWorldFloods‚Äô that is able to send compressed flood maps from sensed images. In particular, we perform a set of experiments to: (1) compare different segmentation models on different processing variables critical for onboard deployment, (2) show that we can produce, onboard, vectorised polygons delineating the detected flood water from a full Sentinel-2 tile, (3) retrain the model with few images of the onboard sensor downlinked to Earth and (4) demonstrate that this new model can be uplinked to the satellite and run on new images acquired by its camera. Overall our work demonstrates that ML-based models deployed in orbit can be updated if new information is available, paving the way for agile integration of onboard and onground processing and "on the fly" continuous learning.</p> </div> </div> </div> </li></ol> <h2 class="year">2022</h2> <ol class="bibliography"></ol> <h2 class="year">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Sci. Rep.</abbr></div> <div id="2021worldfloods" class="col-sm-8"> <div class="title">Towards global flood mapping onboard low cost satellites with machine learning </div> <div class="author"> Gonzalo Mateo-Garcia,¬†<em>Josh Veitch-Michaelis</em>,¬†Lewis Smith, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Silviu Oprea, Guy Schumann, Yarin Gal, Atƒ±lƒ±m G√ºne≈ü Baydin, Dietmar Backes' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">5 more authors</span> </div> <div class="periodical"> <em>Scientific Reports</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dx.doi.org/10.1038/s41598-021-86650-z" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.1038/s41598-021-86650-z</a> </div> <div class="abstract hidden"> <p>Spaceborne Earth observation is a key technology for flood response, offering valuable information to decision makers on the ground. Very large constellations of small, nano satellites‚Äî ‚ÄôCubeSats‚Äô are a promising solution to reduce revisit time in disaster areas from days to hours. However, data transmission to ground receivers is limited by constraints on power and bandwidth of CubeSats. Onboard processing offers a solution to decrease the amount of data to transmit by reducing large sensor images to smaller data products. The ESA‚Äôs recent PhiSat-1 mission aims to facilitate the demonstration of this concept, providing the hardware capability to perform onboard processing by including a power-constrained machine learning accelerator and the software to run custom applications. This work demonstrates a flood segmentation algorithm that produces flood masks to be transmitted instead of the raw images, while running efficiently on the accelerator aboard the PhiSat-1. Our models are trained on WorldFloods: a newly compiled dataset of 119 globally verified flooding events from disaster response organizations, which we make available in a common format. We test the system on independent locations, demonstrating that it produces fast and accurate segmentation masks on the hardware accelerator, acting as a proof of concept for this approach.</p> </div> </div> </div> </li></ol> <h2 class="year">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ADASS</abbr></div> <div id="rascaladass" class="col-sm-8"> <div class="title">RASCAL: Towards automated spectral wavelength calibration</div> <div class="author"> <em>Josh Veitch-Michaelis</em>,¬†and¬†Marco Lam</div> <div class="periodical"> <em>In "Astronomical Data Analysis Software and Systems XXVIII"</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/jveitchmichcaelis/rascal" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> <a href="https://dx.doi.org/10.48550/arXiv.1912.05883" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.48550/arXiv.1912.05883</a> </div> <div class="abstract hidden"> <p>Wavelength calibration is a routine and critical part of any spectral work-flow, but many astronomers still resort to matching detected peaks and emission lines by hand. We present RASCAL (RANSAC Assisted Spectral CALibration), a python library for automated wavelength calibration of astronomical spectrographs. RASCAL implements recent state-of-the-art methods for wavelength calibration and requires minimal input from a user. In this paper we discuss the implementation of the library and apply it to real-world calibration spectra.</p> </div> </div> </div> </li></ol> <h2 class="year">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Nat. Astron.</abbr></div> <div id="nature_iayc" class="col-sm-8"> <div class="title">Assessing the influence of one astronomy camp over 50 years</div> <div class="author"> Hannah Dalgleish,¬†and¬†<em>Josh Veitch-Michaelis</em> </div> <div class="periodical"> <em>Nature Astronomy</em> 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dx.doi.org/10.1038/s41550-019-0965-y" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.1038/s41550-019-0965-y</a> </div> <div class="abstract hidden"> <p>The International Astronomical Youth Camp has benefited thousands of lives during its 50 year history. We explore the pedagogy behind this success, review a survey taken by more than 300 previous participants and discuss some of the challenges the camp faces in the future.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="mateo2019flood" class="col-sm-8"> <div class="title">Flood Detection On Low Cost Orbital Hardware</div> <div class="author"> Gonzalo Mateo-Garcia,¬†Silviu Oprea,¬†Lewis Smith, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Josh Veitch-Michaelis, Atƒ±lƒ±m G√ºne≈ü Baydin, Dietmar Backes, Yarin Gal, Guy Schumann' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">5 more authors</span> </div> <div class="periodical"> <em>In Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop at NeurIPS</em> 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.hadr.ai/previous-years/2019/home-2019" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> <a href="https://dx.doi.org/10.48550/arXiv.1910.03019" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">DOI: 10.48550/arXiv.1910.03019</a> </div> <div class="abstract hidden"> <p>Satellite imaging is a critical technology for monitoring and responding to natural disasters such as flooding. Despite the capabilities of modern satellites, there is still much to be desired from the perspective of first response organisations like UNICEF. Two main challenges are rapid access to data, and the ability to automatically identify flooded regions in images. We describe a prototypical flood segmentation system, identifying cloud, water and land, that could be deployed on a constellation of small satellites, performing processing on board to reduce downlink bandwidth by 2 orders of magnitude. We target PhiSat-1, part of the FSSCAT mission, which is planned to be launched by the European Space Agency (ESA) near the start of 2020 as a proof of concept for this new technology. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ADASS 2019</abbr></div> <div id="mcwhirter2019saving" class="col-sm-8"> <div class="title">Saving Endangered Animals with Astro-Ecology</div> <div class="author"> Paul Ross McWhirter,¬†and¬†<em>Josh Veitch-Michaelis</em> </div> <div class="periodical"> <em>In Astronomical Data Analysis Software and Systems XXVII</em> 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ui.adsabs.harvard.edu/abs/2019ASPC..523...95M" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="abstract hidden"> <p>Conservation science is experiencing an unprecedented challenge in identifying and protecting endangered species across the world. The large stretches of land and sea require innovative solutions for the monitoring of endangered populations. Drones equipped with high resolution cameras with supporting data from satellites have helped to mitigate these challenges. Unfortunately, it is difficult to detect animals from optical images when they might only be a matter of a few pixels across. By deploying thermal infrared cameras on drones to detect animals from their body heat, they can be detected despite their small size in the images. In the thermal infrared band, animals appear as bright sources on a dark, colder background. Through the use of astronomical source detection techniques, these bright animals can be detected although other warm objects lead to false detections. In this paper we demonstrate a technique which uses modern computer vision to build on astronomical source detection algorithms to create a model for the detection and classification of animal thermal profiles in the presence of other warm objects. Using a dataset from Chester Zoo in the UK, we trained a model using 972 frames from a video of the chimpanzee enclosure and achieved excellent results with a training loss of 0.81 and minimal false detections of warm enviromental sources.</p> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CAP</abbr></div> <div id="dalgleish2018international" class="col-sm-8"> <div class="title">The International Astronomical Youth Camp: Lessons Learned in 50 Years</div> <div class="author"> Hannah Dalgleish,¬†and¬†<em>Josh Veitch-Michaelis</em> </div> <div class="periodical"> <em>In Communicating Astronomy with the Public Conference 2018 2nd Edition</em> 2018 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Planet. Space Sci.</abbr></div> <div id="tao2018massive" class="col-sm-8"> <div class="title">Massive stereo-based DTM production for Mars on cloud computers</div> <div class="author"> Yu Tao,¬†Jan-Peter Muller,¬†Panos Sidiropoulos, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Si-Ting Xiong, ARD Putri, SHG Walter, Josh Veitch-Michaelis, Vladimir Yershov' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">5 more authors</span> </div> <div class="periodical"> <em>Planetary and Space Science</em> 2018 </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PhD Thesis</abbr></div> <div id="veitch2017fusion" class="col-sm-8"> <div class="title">Fusion of LIDAR with stereo camera data - an assessment</div> <div class="author"> <em>Josh Veitch-Michaelis</em> </div> <div class="periodical"> 2017 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>This thesis explores data fusion of LIDAR (laser range-finding) with stereo matching, with a particular emphasis on close-range industrial 3D imaging. Recently there has been interest in improving the robustness of stereo matching using data fusion with active range data. These range data have typically been acquired using time of flight cameras (ToFCs), however ToFCs offer poor spatial resolution and are noisy. Comparatively little work has been performed using LIDAR. It is argued that stereo and LIDAR are complementary and there are numerous advantages to integrating LIDAR into stereo systems. For instance, camera calibration is a necessary prerequisite for stereo 3D reconstruction, but the process is often tedious and requires precise calibration targets. It is shown that a visible-beam LIDAR enables automatic, accurate (sub-pixel) extrinsic and intrinsic camera calibration without any explicit targets. Two methods for using LIDAR to assist dense disparity maps from featureless scenes were investigated. The first involved using a LIDAR to provide high-confidence seed points for a region growing stereo matching algorithm. It is shown that these seed points allow dense matching in scenes which fail to match using stereo alone. Secondly, LIDAR was used to provide artificial texture in featureless image regions. Texture was generated by combining real or simulated images of every point the laser hits to form a pseudo-random pattern. Machine learning was used to determine the image regions that are most likely to be stereo- matched, reducing the number of LIDAR points required. Results are compared to competing techniques such as laser speckle, data projection and diffractive optical elements.</p> </div> </div> </div> </li></ol> <h2 class="year">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Int. Arch. ISPRS</abbr></div> <div id="veitch2016enhancement" class="col-sm-8"> <div class="title">Enhancement of stereo imagery by artificial texture projection generated using a LIDAR</div> <div class="author"> <em>Josh Veitch-Michaelis</em>,¬†Jan-Peter Muller,¬†David Walton, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Jonathan Storey, Michael Foster, Benjamin Crutchley' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">3 more authors</span> </div> <div class="periodical"> <em>In International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em> 2016 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CRV</abbr></div> <div id="veitch2016crack" class="col-sm-8"> <div class="title">Crack Detection in ‚ÄúAs-Cast‚Äù Steel Using Laser Triangulation and Machine Learning</div> <div class="author"> <em>Josh Veitch-Michaelis</em>,¬†Yu Tao,¬†Dave Walton, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Jan-Peter Muller, Benjamin Crutchley, Jonathan Storey, Christopher Paterson, Andrew Chown' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">5 more authors</span> </div> <div class="periodical"> <em>In 13th Conference on Computer and Robot Vision (CRV)</em> 2016 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Int. Arch. ISPSRS</abbr></div> <div id="tao2016optimised" class="col-sm-8"> <div class="title">An Optimised System for Generating Multi-Resolution DTMs using NASA MRO Datasets</div> <div class="author"> Yu Tao,¬†Jan-Peter Muller,¬†Panos Sidiropoulos, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Josh Veitch-Michaelis, Vladimir Yershov' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">2 more authors</span> </div> <div class="periodical"> <em>In International Archives of the Photogrammetry, Remote Sensing &amp; Spatial Information Sciences</em> 2016 </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2024 Josh Veitch-Michaelis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>